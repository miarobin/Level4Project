{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as pyplot\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, KBinsDiscretizer\n",
    "from sklearn.model_selection import train_test_split, learning_curve, StratifiedShuffleSplit\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "import DataPreprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtaining and nicely arranging data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Obtain & process data CSV\n",
    "me_train, mom_train = DataPreprocessing.csv('NLO/MG_uux/me_2Jet_1000000.csv','NLO/MG_uux/mom_2Jet_1000000.csv', frac=0.1)\n",
    "me_test, mom_test = DataPreprocessing.csv('NLO/MG_uux/me_2Jet_100000.csv', 'NLO/MG_uux/mom_2Jet_100000.csv', frac=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Obtain & process data NPY\n",
    "me_train, mom_train = DataPreprocessing.npy('LO/MG_uuxg/3Jet_3000000.npy', 'LO/LO_3_0.01_NJet/PS3_0.01_3000000.npy', ['1,3', '2,3'], 1000, frac=0.1)\n",
    "me_test, mom_test = DataPreprocessing.npy('LO/MG_uuxg/3Jet_500000.npy', 'LO/LO_3_0.01_NJet/PS3_0.01_500000.npy', ['1,3', '2,3'], 1000, frac=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding some extra features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Data transformation\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()), #Rescale Data.\n",
    "    ('kbins', KBinsDiscretizer(n_bins=1000)) #Checking convergence as bins.\n",
    "])\n",
    " \n",
    "mom_train = pipeline.fit_transform(mom_train) #Rescale on training set\n",
    "mom_test = pipeline.transform(mom_test) #Rescale on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg = LinearRegression().fit(mom_train, me_train)\n",
    "\n",
    "me_predict_lin = linreg.predict(mom_test) #Prediction on test set\n",
    "lin_mse = mean_squared_error(me_test, me_predict_lin) \n",
    "print('RMSE: {}').format(np.sqrt(lin_mse))\n",
    "\n",
    "\n",
    "lin_perc = np.mean(100*np.divide(np.abs(me_test - me_predict_lin), me_test))\n",
    "print('Percentage Error: {}').format(lin_perc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.std(me_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting Learning Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Plotting a Learning Curve\n",
    "split = StratifiedShuffleSplit() #Collects data evenly about mean to put into validation sets\n",
    "train = split.split(mom_train, pd.cut(me_train, bins = 200)) #But are we testing on something we've trained..?\n",
    "\n",
    "train_sizes, train_scores, test_scores = learning_curve(\n",
    "        linreg, mom_train, me_train, scoring='neg_mean_squared_error',\n",
    "        cv=5, shuffle=True, train_sizes=np.linspace(0.01, 0.1, 6), \n",
    "        n_jobs=1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot.figure()\n",
    "\n",
    "train_scores_mean = np.sqrt(-np.mean(train_scores, axis=1))\n",
    "test_scores_mean = np.sqrt(-np.mean(test_scores, axis=1))\n",
    "\n",
    "pyplot.xlabel(\"Training examples\")\n",
    "pyplot.ylabel(\"RMSE\")\n",
    "pyplot.savefig('LearningCurveKBins')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std(me_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot accuracy vs number of bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def changeBins(n_bins, input_train, input_test, output_train, output_test):\n",
    "    ##Data transformation\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()), #Rescale Data.\n",
    "        ('kbins', KBinsDiscretizer(n_bins=n_bins)) #Checking convergence as bins.\n",
    "    ])\n",
    "\n",
    "    temp_train = pipeline.fit_transform(input_train) #Rescale on training set\n",
    "    temp_test = pipeline.transform(input_test) #Rescale on test set\n",
    "    \n",
    "    linreg = LinearRegression().fit(temp_train, output_train)\n",
    "\n",
    "    me_predict = linreg.predict(temp_test) #Prediction on test set\n",
    "    lin_mse = mean_squared_error(output_test, me_predict) \n",
    "    \n",
    "    lin_perc = np.mean(100*np.divide(np.abs(output_test - me_predict), output_test))\n",
    "    \n",
    "    return np.sqrt(lin_perc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Obtain & process data\n",
    "me_train, mom_train = DataPreprocessing.npy('LO/MG_uuxg/3Jet_3000000.npy', 'LO/LO_3_0.01_NJet/PS3_0.01_3000000.npy', frac=0.1)\n",
    "me_test, mom_test = DataPreprocessing.npy('LO/MG_uuxg/3Jet_500000.npy', 'LO/LO_3_0.01_NJet/PS3_0.01_500000.npy', frac=0.1)\n",
    "\n",
    "n_bins_arr = range(10000, 15000, 5000)\n",
    "result = []\n",
    "for n_bins in n_bins_arr:\n",
    "    temp = changeBins(n_bins, mom_train, mom_test, me_train, me_test)\n",
    "    print(temp)\n",
    "    result.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot.xlabel('Number of Bins')\n",
    "pyplot.ylabel('RMSE')\n",
    "pyplot.title('Point k at which kBins overfits')\n",
    "pyplot.plot(n_bins_arr, result)\n",
    "pyplot.savefig('RMSE_kBins_Overfit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(me_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.std(me_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
