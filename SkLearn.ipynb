{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as pyplot\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Minkowski product of 4-vectors p1, p2.\n",
    "def m_prod_arr(p1, p2):\n",
    "    return np.multiply(p1[:,0], p2[:,0]) - np.sum(np.multiply(p1[:,1:], p2[:,1:]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocessing(me_filename, mom_filename, frac=1):\n",
    "    ##Data Aquisition\n",
    "    me_raw = np.load(me_filename, allow_pickle=True) #Matrix elements\n",
    "    mom_raw = np.load(mom_filename, allow_pickle=True, encoding='bytes') #4-momenta of inputs\n",
    "    mom_raw = np.array([np.array(element) for element in mom_raw])\n",
    "    \n",
    "    me_raw=me_raw[:int(frac*len(me_raw))]\n",
    "    mom_raw=mom_raw[:int(frac*len(mom_raw))]\n",
    "    \n",
    "    p_12 = mom_raw[:,2] + mom_raw[:,3] #p1+p2\n",
    "    p_13 = mom_raw[:,2] + mom_raw[:,4] #p1+p3\n",
    "    p_23 = mom_raw[:,3] + mom_raw[:,4] #p2+p3\n",
    "\n",
    "    s_12 = m_prod_arr(p_12, p_12) #center of mass energies of two of three beams\n",
    "    s_13 = m_prod_arr(p_13, p_13)\n",
    "    s_23 = m_prod_arr(p_23, p_23)\n",
    "    \n",
    "    ##Flatten Momentum\n",
    "    mom = np.array([np.ndarray.flatten(np.array(element)[2:]) for element in mom_raw])\n",
    "\n",
    "    ##Reformat Matrix Element (remove divergent behaviour)\n",
    "    me = np.multiply(np.multiply(me_raw, s_13), s_23)/(s_12+s_13+s_23)\n",
    "    \n",
    "    return(me, mom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Obtain & process data\n",
    "me_train, mom_train = data_preprocessing('LO_3_MG/3Jet_3000000.npy', 'LO_3_0.01_NJet/PS3_0.01_3000000.npy', frac=0.1)\n",
    "me_test, mom_test = data_preprocessing('LO_3_MG/3Jet_500000.npy', 'LO_3_0.01_NJet/PS3_0.01_500000.npy', frac=0.1)\n",
    "\n",
    "##Rescale\n",
    "scaler = StandardScaler()\n",
    "\n",
    "mom_train = scaler.fit_transform(mom_train) #Rescale on training set\n",
    "mom_test = scaler.transform(mom_test) #Rescale on test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/model_selection/_search.py:266: UserWarning: The total space of parameters 1 is smaller than n_iter=10. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0016273754965707213\n"
     ]
    }
   ],
   "source": [
    "##Random Forest Model\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_grid = {'n_estimators': [10], 'max_features': [2] }\n",
    "\n",
    "forest_reg = RandomForestRegressor() \n",
    "\n",
    "#Grid search through parameter space\n",
    "rand_search = RandomizedSearchCV(forest_reg, param_grid, cv=5, scoring='neg_mean_squared_error', return_train_score=True)\n",
    "rand_search.fit(mom_train, me_train)\n",
    "\n",
    "me_predict = rand_search.predict(mom_test)\n",
    "forest_mse = mean_squared_error(me_test, me_predict)\n",
    "print(np.sqrt(forest_mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Polynomial Fit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.150695814584132e-14\n",
      "8.230550588993383e-13\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "poly_features = PolynomialFeatures(degree=2)\n",
    "poly_train = poly_features.fit_transform(mom_train)\n",
    "poly_test = poly_features.transform(mom_test)\n",
    "\n",
    "linreg = LinearRegression().fit(poly_train, me_train)\n",
    "\n",
    "me_predict_lin = linreg.predict(poly_test) #Prediction on test set\n",
    "lin_mse = mean_squared_error(me_test, me_predict_lin) \n",
    "print(np.sqrt(lin_mse))\n",
    "\n",
    "\n",
    "lin_perc = np.mean(100*np.divide(np.abs(me_test - me_predict_lin), me_test))\n",
    "print(lin_perc)\n",
    "\n",
    "#elasticnet = ElasticNet(alpha=0.01, l1_ratio=0.5)\n",
    "#elasticnet.fit(poly_train, me_train)\n",
    "\n",
    "#poly_predict = elasticnet.predict(poly_test)\n",
    "#poly_mse = mean_squared_error(me_test, poly_predict)\n",
    "#print(np.sqrt(poly_mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
